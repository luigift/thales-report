
\iftoggle{rapport} {
  \chapter{Introduction}
}{}

\begin{center}
  {\color{green}EN VERT SONT DES PARTIES QUE NE SONT PAS ENCORE FINI}
\end{center}

\section{Contexte}
La perception de l'environment par machines est indispensable pour son integration à la vie quotidienne. Compétences telle comme se localiser, prise de décisions et capacité d'apprentissage sont nécessaire pour la réalisation de les plus simples tâches. Dans cet étude, on s'intéresse à la compréhension d'éléments constituent d'une scène, sujet récurrent dans le domaine de la vision par ordinateur. Plusieurs approches proposés dans la littérature explorent une sous-partie du \textit{pipiline} de la reconnaissance pour faire face au difficile défi de représenter la forme visuelle des objets, pendent qu'autres s'intéressent à l'utilisation du système de reconnaissance pour tâches de recherche dans l'environnement et saisie {\color{blue}(empoignement)} , par exemple.

\section{Objectifs}

Notre démarche correspond, initialement, à l'intégration de techniques de l'état de l'art pour arriver à un système fonctionnel de reconnaissance incorporé sur une plateforme mobile équipée d'un capteur RGB-D capable. Dans une première temps, la plateforme est capable d'acquérir une base de données d'images d'un objet et, ensuite, d'utiliser ces informations apprises pour vérifier si un objet candidat est ou non celui présenté auparavant, et, finalement, renforcer sa perception avec les information de son déplacement pour lever les possibles ambiguités.

% Vision par ordinateur - Reconnaissance d'objets multi-vue - Robotique

\section{État de l'art}

La majorité de la littérature traite le problème de la reconnaissance d'après une seule image de l'objet. Typiquement, une ensemble de \textit{features} est extrait et, ensuite, comparé aux modèles d'objets présents dans une base de données initiale, en contraste aux méthodes directes, comme deep learning, où l'image d'entré est associée directement avec des classes des objets correspondants au compromis d'une étape d'entrainement importante d'apprentissage de \textit {features}, encore plus dans un espace à 3 dimensions provenant du capteur RGB-D. Innombrables exemples d'applications de la reconnaissance mono-vue dans le domaine de la robotique existent pour la navigation sémantique 
\textbf{\textit{Neural Network Fusion of Color, Depth and Location for Object Instance Recognition on a Mobile Robot}} couplé avec l'estimation de pose pour la saisie de l'objet ref: \textbf{\textit{Three-Dimensional Object Recognition and 6 DoF Pose Estimation}} ou encore pour la recherche d'objets dans l'environnement ref: \textbf{\textit{Object Search and Localization for an Indoor Mobile Robot}} .

Un grand effort était fait pour améliorer l'extraction, le \textit {matching}, ainsi que le \textit{features} elles-mêmes pour qu'elles soient invariantes à transformations affinés de l'image et représentatives de l'objet. Ce traitement classique a l’avantage d'être, à la fois modulaire, avec des étapes bien définies de segmentation, extraction de features, classification et post-traitement, et, au même temps, d'avoir des résultats satisfaisants d'après une implémentation plus immédiate. 



Malgré son intérêt dans certains cas, rapidement on s'aperçoit de limitations lors que vues ambiguës apparaissent. Un premier travail s'inspire de la continuité, temporalité et séquentialité des observations dans la reconnaissance chez les humains pour augmenter la représentativité des modèles d'objet et, ainsi, surmonter las limitation de la reconnaissance mono-vue. Au temps que d'autres, partent sur des modèles CAD à trois dimension, la description de contours et les graphes ref:\textit{3d object recognition through next view planning} pour avoir ce gain en représentativité. En spécial, les graphes d'aspect permettent une représentation basé sur une composition d'images de points de vue différents et les liens entre elles.  Les vues représentatives, nommés \textit{key-Frames}, peuvent être choisi avec des politiques aléatoire, constant ou à la recherche d'événements visuels.
  
Pendent que d'autres vont encore plus loin en suggérant une reconnaissance active où une estimation de quel serait le meilleur déplacement pour lever des ambiguïtés repositionne le capteur par la réduction de l'entropie en s'utilisant des probabilités de reconnaissance antérieures  ref:\textbf{\textit{Active Object Recognition in Parametric Eigenspace}} où encore par estimation des faces cachées de l'objet ref:\textbf{\textit{Next Best View}}. Finalement, ref:\textbf{\textit{Active Object Recognition on a Humanoid Robot}} traite ce même problème comme un problème de localisation et suivi par un filtre de particule.




