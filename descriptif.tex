\chapter{Introduction}
\section{Descriptif du sujet et problématique}

La reconnaissance d'objets est un sujet récurrent dans le domaine de la vision par ordinateur. La possibilité de comprendre quels éléments constituent une image est d'un grand intérêt, par exemple, pour l'automatisation de la vidéo protection.  Plusieurs modèles sont proposés dans la littérature pour faire face au difficile défi de représenter la forme visuelle des objets, des plus simples aux plus complexes. L'activité de vision est très liée à la robotique, notamment la sélection des zones à observer et la décision de s'approcher pour observer de plus près un objet et, simultanément, pour lever les ambiguités de la reconnaisance.

La mise en oeuvre se décompose suivant les tâches: 
\begin{itemize}
\item Etude de l’état de l’art
\item Définition de l’architecture système 
\item Développement de la solution logiciel et matériel 
\item Test et démonstration sur une plateforme robotique
\end{itemize}

\section{Objectifs du stage.}
Le but du stage est d'avoir une plateforme mobile automatique capable, dans une première version, d'acquérir une base de données d'images d'un objet et, ensuite, capable d'utiliser ces informations apprises par modèle pour vérifier dans un environnement si un objet candidat est ou non celui présenté auparavant. Pour cela, la plateforme mobile, qui est dans le cadre du stage un robot terrestre, est sensée chercher le point de vue qui maximise la reconnaissance de l'objet.


\section{Thématiques du stage.}
Vision par ordinateur - Reconnaissance d'objets active - Robotique


\subsection{Modèle et Reconnaissance}
La représentation de l’objet est essentielle pour sa reconnaissance. Savoir quel déplacement physique peut ramener à des vues intéressantes augmente drastiquement les chances de bien le reconnaitre. Pour cela, les chaînes de Markov cachées pourraient être d'une grande utilité, car l'évolution des observations estime l'état courant. Autrement, des méthodes plus géométriques comme celles qui sont utilisées dans le \textit{Best Next View} semblent aussi une bonne approche du problème. Finalement, le mélange entre les deux méthodes, statistique et géométrique est considéré.


\section{Positionnement du sujet par rapport à l’existant.}
Étant donné un objet candidat dans l'environnement, sélectionné manuellement ou à l'aide d’une méthode automatique comme la saillance visuelle, on s'intéresse à l'utilisation d'un robot pour augmenter les chances de reconnaissance par des algorithmes déjà existants. La détection d'objets par un robot mobile est traitée dans des articles comme : \textit{Object Search and Localization for an Indoor Mobile Robot} [1] et \textit{Learning Search Heuristics for Finding Objects in Structured Environments} [2]. Pourtant, dans les deux cas, l'intérêt central est d'effectuer une recherche/exploration dans un environnement, dont le plan est connu par avance, pour retrouver un objet donné a priori, avec peu d'intérêt pour la reconnaissance de l'objet lui-même.  Autrement, l'algorithme \textit{Next Best View} semble être intéressant pour notre problème. Pour l'instant, son utilisation était dédiée à la création d'un modèle 3D du objet.


\section{Method de segmentation de l'objet}

La segmentation de l'objet consiste de la soustractraction d'un image ou nuages de points brute. En autres mots, differencie les elements non constituents du objet de lui même. Pour pouvoir traiter ce problème plus facilement, quelques contraintes étaient imposées :
- L'objet se trouve par terre, autrement, le plan de support de l'objet est le même du capteur.
- Le plan plus important, plus grand nombre de points dans la nuage, correspond au sol, ce qui peut être traduit par un une image dont le sol rempli un partie important.
- Une dernière contrainte impose que l'objet est au centre de l'image, ce qui va être atteint à l'aide du déplacement du robot. Alors, les objets qui touches les bordes de l'image acquis sont pas prise en compte.

Après ces contraintes, (Ayant ces contraintes en tête), la segmentation est faite dans les étapes suivantes :
\begin{numerate}
  \item Utilisation du méthode de RANSAC* pour la détection du plus important plan dans la scène, qui, par hipothèse, correspondra au sol.

  \item Filtrage de points distants, considérés comme erreur de mesure.

  \item Calcule de la normale des autres superficies comprises dans la scène

  \item Élimination de murs. Les murs sont considerés comme de plans de 
taille sufisament grande, d'après un certain seuil, dont la normale est perpendiculaire à celle du plan consideré comme sol.

   \item Projection des points appartenaints aux objets dans le plan du sol. 

   \item Determination du enveloppe convexe correspondant au sol detecte'.

   \item Réduction de la densité de discretization pour accelerer létape de clustering.

   \item Clustering de les projections des objets sur lénveloppe. Pour le clustering l'argorithme sén sers du *point growing*

   \item Retour à discretization initiale.

   \item Extraction de thumbnails, bouding boxes et autre informations pertinants aux objets detectes.
\end{numerate}

\section{Déplacement du robot}

Le robot est équipé de trois roues. Les deux roues simétriques arrières sont motorisés et sont responsable pour le deplacement lui même, au même temps que la dernière sert à donner un support pour la partie derrière de la carrocerie. Les moteurs sont controles à partir de commandes series, pre-establis pour le fabricant, qui definissent la vitesse de roulement. 

La combinaison de les rotations des deux roues motorises dans les deux senses possibles permets au robot d'avoir les comportements suivants: 

\begin {itemize}
    \item Déplacement en ligne droite : équivalent a les deux roues rolant avec la meme vitesse et dans le même sense.

    \item Déplacement en arc de cercle : La difference entre les vitesses de roues résulta dans un mouvement de cercle. Le rapport entre cette difference pemettre définir la courbature de la trajectoir.

    \item Rotation : Dans ce cas, les deux roues sont commandees à la même vitesse, mais avec de sense differents.
\end{itemize}

*Ilustration*

\subsection{Problèmes de déplacement}
La combinaison de ces mouvements permet au robot de acceder n' import quel position du space. Cependant, mouvements de petit amplitude *tendem* à apporter plus d'incertitude à cause des erreuse de démarrage et arrêt. Ainsi, des grands mouvments sont préférés en comparaison aux *petits*.

- Roue de support
Cette roue a comme fonctionnalité supporter le poids du robot. La roulette instaleé initialement a  deux axes de rotation. Pourtant, mouvements de rotation du robot aligne la roulette ortgonalement au sense du prochain mouvement ce que crees un torche que *devine/desvia* la trajectoir voulu. Une tentative d'installer une roulette bille omnidirectionnelle était frusté car le mouvement sur la moquette et avec le poids du robot dessous donnait des mouvements aléatoires.

\section{Etude de l'état de l'art}
La majorité de la literature traite le problème de la reconnaissance d'après une seule image de l'objet. Typiquement, une ensemble de \textit{features} est extrait et, ensuite, comparée avec des modèles d'objets presents dans une base de données initiale. Un grand effort était fait pour améliorer l'extraction, le \textit{matching} des \textit{features} ainsi que les \textit{features} elles mêmes pour qu'elles soient invariantes à transformations affinés de l'image et representatives de l'objet.
Ce méthode est intéressant dans certains cas, mais rapidement on s'apperçois de ces limitations lors que vues ambigues apparaissent, par exemple.

Selon les études réalisés en \textbf{reference [5]}, les humans sembles construir un modèle géometrique rotationnel continu, en autre mots, une composition de vues sequentielles qui font le lien entre differentes faces du objet. En plus, d'autre étude suggère que l'ensemble de vues augmente le taux de reconnaissance de l'objet.

L'intérêt de cet étude est d'avoir une reconnaissance active de l'objet faite par une plateforme mobile.  


1. View-based dynamic object recognition based on human perception 

Cet article *discorre* sur l'importance de une observation temporelle pour la réconnaissance des objets, fait remarqué dans le processus de reconnaissance humaine.

La méthode utilisé consisté à partir de l'image initial prise comme key-frame où ses features sont calculées. Ensuite, ses features sont trackées jusqu'à diminuition de features détectées tombe à un nombre inferieur à un seuil définis à priori. La reconnaissance est faite par le comparaison de 


2. Active Object Recognition in Parametric Eigenspace
Matrice de convariance entre images à partire de correlation entre elles. Les vecteurs propres de cette matrice sont utilis'ees comme base du space. Une image de test est, ensuite, projet'e sur ce base et l'image est identifi'e avec celle correspondent au plus proche, au sense eucliidien, vecteur de base. Cela apporte aussi une estimation de la *pose* du objet, une fois que les images sont labelis'ees. 
Pour d'ecouvrir quelle est la prochaine action/deplacement à faire, l'algorithme propose la r'eduction de l'entopie en s'utilisant des probabilit'es de reconnaissance à partir des informations ant'erieures.


3. 
Un troisième approche est celui d'identifier l'invariance à certains vues de features, pour après construir une arbre hierarchique que characteriserait chaque objet....

4. TableTop Algorithm

segmentation
the table is detected by finding the dominant plane in the point cloud using RANSAC;
points above the table are considered to belong to graspable objects. We use a clustering algorithm to identify individual objects. We refer to the points corresponding to an individual object as clusters.
recognition
for each cluster, a simple iterative fitting technique (a distant cousin of ICP) is used to see how well it corresponds to each mesh in our database of models. If a good fit is found, the database id of the model is returned along with the cluster.
note that our current fitting method operates in 2D, since based on our assumptions (object resting upright on the known surface of the table) the other 4 dimensions are fixed

\section{Matériels}

\subsection{Types d'outils et méthodes utilisés.}

\subsection{Outils matériels et logiciels}
En ce que concerne les aspects matériels, le robot bimoteur Wifibot v2, qui transporte un ordinateur embarqué, sera utilisé comme plateforme mobile. L'acquisition des données est faite par une camera RGB-D portée par une tourelle qui permet son orientation indépendamment du positionnement du robot.
Par rapport au choix logiciel, l'environnement robotique ROS a été adopté pout avoir les deux bibliothèques pour gérer les nuages de points,  bibliothèques Freenect et PCL - Point Cloud Library, et d'autres nombreux outils de contrôle du robot et sauvegarde d'informations.

\subsection{ Description de la plateforme mobile }

Nom :Robot Wifibot v2
Largeur : 35 cm
Longueur : 30 cm
Hauteur : 
Oridnateur portable embarqué : Intel Atom
*shelf* pour les capteurs
Batterie :

\subsection{Description Ordinateur Portable}

HP ....
Processeur : Intel i5 ....
HD : 
RAM :


\subsection{Restrictions logiciels}
L' ordinateur embarque' a un puissance de calcul reduit ce que ne permet pas que le node d'acquisition (openni2_launch) tourne correctment. La solution pour l'instant c'était de connecter le capteur Asus sur l'ordinateur portable HP.

Description de le capteur RGB-D :
Asus Xtion Pro Live
Résolution du capteur infrarouge
Résolution de l'image :
Range de vision : ** degrees:

L'acquisition des données est fait par une camera RGB-D à l'aide des bibliothèques Freenect et PCL.

Autrement, L'environement ROS était notre choix logiciel, renforcé par le fait d'avoir les deux bibliothèques pour gerencier les nouages de points et d'autres nombreux outils de contrôle du robot et sauvegarde d'information, pour faire le lien entre le plusieurs composantes physiques.

\section{ Base de données}

\subsection{Acquisition de la base des données}
L'asservissement du robot permet d'obtenir plusieurs vues d'un certain objet. Pour l'instant le robot suit une trajectoire circulaire autour de l'objet cible, commandé en boucle ouverte. La base de données est constituée, pour chaque vue, d'une image RGB, d'un nuage de points et des objets segmentés, ainsi que la commande envoyée au robot et, par conséquent, sa trajectoire approchée.

\subsection{Constituition detailée}

Les images sont sauvegardées à l'aide de la librarie OpenCv dans le format 8_U et .png (Portable Network Graphics).

Les nauges de points sont sauvegardées dans le format .pcd (Point Cloud Data).

Pour sauvegarder les information *provenientes* de la segmentation, les [it]topics de sorti sont souscrit avec rosbag pendent le deplacement du robot. Les messages sauvegardes sont le suivants :

\begin{itemize}
\item v_objects_clouds : Vector de nuages de points obtenues pour chaque objet 

\item v_objects_image_and_mask : Sousimages et mask de chaque objet

\item v_object_

\end{itemize}


\section{Travaux déjà effectués.}
\begin{itemize}
    \item[\checkmark] Mise en place de l'architecture et des protocoles de communication entre composants physiques.
    \item[\checkmark] Étude bibliographique initiale pour situer le travail par rapport à l'existant.
    \item[\checkmark] Implémentation de l'asservissement d'une caméra PTZ par rapport au retour d'un algorithme de tracking.
    \item[\checkmark] Aperçu de certaines limitations de la caméra PTZ qui a été remplacée par une caméra RGB-D.
    \item[\checkmark] Utilisation d'un algorithme de segmentation d'objets possibles dans la scène.
    \item[\checkmark] Asservissement en boucle ouvert du robot pour la création de la base de données.
    \item[\checkmark] Premiers tests pour l'acquisition de la base des données.
\end{itemize}

\section{Calendrier prévisionnel des tâches restant à effectuer.}
Fin Mai
\begin{itemize}
    \item Résolution des problèmes trouvés lors des premiers tests pour la création de la base de données.
    \item Validation de la base de données. Représentativité et reproduction.
\end{itemize}

Juin-Juillet
\begin{itemize}
    \item Étude approfondie de l’état de l'art des modèles et méthodes qui puissent être utiles pour notre problème.
    \item Mise en place de la solution et du modèle proposé.
    \item Premiers tests et ajustements nécessaires.
\end{itemize}

Août
\begin{itemize}
    \item Mise en œuvre de la solution complète.
    \item Validation finale.
\end{itemize}

\section{Bibliographie}

[1] Active Object Recognition in Parametric Eigenspace

[2] View-based dynamic object recognition based on human perception

[3]

[4]

[5]

[6]

